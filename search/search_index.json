{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>A G2P library in PyTorch</p> <p> </p> <p>DeepPhonemizer is a library for grapheme to phoneme conversion based on Transformer models.  It is intended to be used in text-to-speech production systems with high accuracy and efficiency. You can choose between a forward Transformer model (trained with CTC) and its autoregressive counterpart. The former is faster and more stable while the latter is slightly more accurate.</p> <p>The main advantages of this repo are:</p> <ul> <li>Easy-to-use API for training and inference.</li> <li>Multilingual: You can train a single model on several languages.</li> <li>Accuracy: Phoneme and word error rates are comparable to state-of-art. </li> <li>Speed: The repo is highly optimized for fast inference by using dictionaries and batching.</li> </ul> <p>Check out the inference and training tutorials on Colab! </p> <p>Read the documentation at: https://as-ideas.github.io/DeepPhonemizer/</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install deep-phonemizer\n</code></pre>"},{"location":"#quickstart","title":"Quickstart","text":"<p>Download the pretrained model: en_us_cmudict_ipa_forward</p> <pre><code>from dp.phonemizer import Phonemizer\n\nphonemizer = Phonemizer.from_checkpoint('en_us_cmudict_ipa.pt')\nphonemizer('Phonemizing an English text is imposimpable!', lang='en_us')\n\n'fo\u028an\u026ama\u026az\u026a\u014b \u00e6n \u026a\u014bgl\u026a\u0283 t\u025bkst \u026az \u026amp\u0259z\u026amp\u0259b\u0259l!'\n</code></pre>"},{"location":"#training","title":"Training","text":"<p>You can easily train your own autoregressive or forward transformer model.  All necessary parameters are set in a config.yaml, which you can find under:</p> <pre><code>dp/configs/forward_config.yaml\ndp/configs/autoreg_config.yaml\n</code></pre> <p>for the forward and autoregressive transformer model, respectively.</p> <p>Distributed training is supported. You can specify which GPUs to utilize by setting CUDA_VISIBLE_DEVICES env variable:</p> <pre><code>CUDA_VISIBLE_DEVICES=0,1 python run_training.py\n</code></pre> <p>Inside the training script prepare data in a tuple-format and use the preprocess and train API:</p> <pre><code>from dp.preprocess import preprocess\nfrom dp.train import train\n\ntrain_data = [('en_us', 'young', 'j\u028c\u014b'),\n                ('de', 'ben\u00fctzten', 'b\u0259n\u028ft\u0361stn\u0329'),\n                ('de', 'gew\u00fcrz', '\u0261\u0259v\u028f\u0281t\u0361s')] * 1000\n\nval_data = [('en_us', 'young', 'j\u028c\u014b'),\n            ('de', 'ben\u00fctzten', 'b\u0259n\u028ft\u0361stn\u0329')] * 100\n\nconfig_file = 'dp/configs/forward_config.yaml'\n\npreprocess(config_file=config_file,\n           train_data=train_data,\n           val_data=val_data,\n           deduplicate_train_data=False)\n\nnum_gpus = torch.cuda.device_count()\n\nif num_gpus &gt; 1:\n    mp.spawn(train, nprocs=num_gpus, args=(num_gpus, config_file))\nelse:\n    train(rank=0, num_gpus=num_gpus, config_file=config_file)\n</code></pre> <p>Model checkpoints will be stored in the checkpoints path that is provided by the config.yaml.</p>"},{"location":"#inference","title":"Inference","text":"<p>Load the phonemizer from a checkpoint and run a prediction. By default, the phonemizer stores a  dictionary of word-phoneme mappings that is applied first, and it uses the Transformer model only to predict out-of-dictionary words.</p> <pre><code>from dp.phonemizer import Phonemizer\n\nphonemizer = Phonemizer.from_checkpoint('checkpoints/best_model.pt')\nphonemes = phonemizer('Phonemizing an English text is imposimpable!', lang='en_us')\n</code></pre> <p>If you need more inference information, you can use following API:</p> <pre><code>from dp.phonemizer import Phonemizer\n\nresult = phonemizer.phonemise_list(['Phonemizing an English text is imposimpable!'], lang='en_us')\n\nfor word, pred in result.predictions.items():\n  print(f'{word} {pred.phonemes} {pred.confidence}')\n</code></pre>"},{"location":"#pretrained-models","title":"Pretrained Models","text":"Model Language Dataset Repo Version en_us_cmudict_ipa_forward en_us cmudict-ipa 0.0.10 en_us_cmudict_forward en_us cmudict 0.0.10 latin_ipa_forward en_uk, en_us, de, fr, es wikipron 0.0.10"},{"location":"#torchscript-export","title":"Torchscript Export","text":"<p>You can easily export the underlying transformer models with TorchScript:</p> <pre><code>import torch\nfrom dp.phonemizer import Phonemizer\n\nphonemizer = Phonemizer.from_checkpoint('checkpoints/best_model.pt')\nmodel = phonemizer.predictor.model\nphonemizer.predictor.model = torch.jit.script(model)\nphonemizer('Running the torchscript model!')\n</code></pre>"},{"location":"#maintainers","title":"Maintainers","text":"<ul> <li>Christian Sch\u00e4fer, github: cschaefer26</li> </ul>"},{"location":"#references","title":"References","text":"<p>Transformer based Grapheme-to-Phoneme Conversion</p> <p>GRAPHEME-TO-PHONEME CONVERSION USING LONG SHORT-TERM MEMORY RECURRENT NEURAL NETWORKS</p>"},{"location":"CONTRIBUTING/","title":"Contribution Guide","text":"<p>We welcome any contributions whether it's,</p> <ul> <li>Submitting feedback</li> <li>Fixing bugs</li> <li>Or implementing a new feature.</li> </ul> <p>Please read this guide before making any contributions.</p>"},{"location":"CONTRIBUTING/#submit-feedback","title":"Submit Feedback","text":"<p>The feedback should be submitted by creating an issue at GitHub issues. Select the related template (bug report, feature request, or custom) and add the corresponding labels.</p>"},{"location":"CONTRIBUTING/#fix-bugs","title":"Fix Bugs:","text":"<p>You may look through the GitHub issues for bugs.</p>"},{"location":"CONTRIBUTING/#implement-features","title":"Implement Features","text":"<p>You may look through the GitHub issues for feature requests.</p>"},{"location":"CONTRIBUTING/#pull-requests-pr","title":"Pull Requests (PR)","text":"<ol> <li>Fork the repository and a create a new branch from the master branch.</li> <li>For bug fixes, add new tests and for new features please add changes to the documentation.</li> <li>Do a PR from your new branch to our <code>master</code> branch of the original DeepPhonemizer repo.</li> </ol>"},{"location":"CONTRIBUTING/#documentation","title":"Documentation","text":"<ul> <li>Make sure any new function or class you introduce has proper docstrings.</li> </ul>"},{"location":"CONTRIBUTING/#testing","title":"Testing","text":"<ul> <li>We use unittest for our testing. Make sure to write tests for any new feature and/or bug fixes.</li> </ul>"},{"location":"CONTRIBUTING/#main-contributor-list","title":"Main Contributor List","text":"<p>We maintain a list of main contributors to appreciate all the contributions.</p>"},{"location":"LICENSE/","title":"LICENSE","text":"<p>MIT License</p> <p>Copyright (c) 2021 Axel Springer News Media &amp; Tech GmbH &amp; Co. KG - Ideas Engineering</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"phonemizer/","title":"Phonemizer","text":""},{"location":"phonemizer/#class-phonemizer","title":"class Phonemizer","text":""},{"location":"phonemizer/#__init__","title":"__init__","text":"<pre><code>def __init__(predictor, lang_phoneme_dict)\n</code></pre> <p>Initializes a phonemizer with a ready predictor.</p>"},{"location":"phonemizer/#args","title":"Args","text":"<ul> <li> <p>predictor (Predictor): Predictor object carrying the trained transformer model.</p> </li> <li> <p>lang_phoneme_dict (Dict[str, Dict[str, str]], optional): Word-phoneme dictionary for each language.</p> </li> </ul>"},{"location":"phonemizer/#__call__","title":"__call__","text":"<pre><code>def __call__(text, lang, punctuation, expand_acronyms, batch_size)\n</code></pre> <p>Phonemizes a single text or list of texts.</p>"},{"location":"phonemizer/#args_1","title":"Args","text":"<ul> <li> <p>text (str): Text to phonemize as single string or list of strings.</p> </li> <li> <p>lang (str): Language used for phonemization.</p> </li> <li> <p>punctuation (str): Punctuation symbols by which the texts are split.</p> </li> <li> <p>expand_acronyms (bool): Whether to expand an acronym, e.g. DIY -&gt; D-I-Y.</p> </li> <li> <p>batch_size (int): Batch size of model to speed up inference.</p> </li> </ul>"},{"location":"phonemizer/#returns","title":"Returns","text":"<ul> <li>Union[str, List[str]]: Phonemized text as string, or list of strings, respectively.</li> </ul>"},{"location":"phonemizer/#phonemise_list","title":"phonemise_list","text":"<pre><code>def phonemise_list(texts, lang, punctuation, expand_acronyms, batch_size)\n</code></pre> <p>Phonemizes a list of texts and returns tokenized texts, phonemes and word predictions with probabilities.</p>"},{"location":"phonemizer/#args_2","title":"Args","text":"<ul> <li> <p>texts (List[str]): List texts to phonemize.</p> </li> <li> <p>lang (str): Language used for phonemization.</p> </li> <li> <p>punctuation (str): Punctuation symbols by which the texts are split. (Default value = DEFAULT_PUNCTUATION)</p> </li> <li> <p>expand_acronyms (bool): Whether to expand an acronym, e.g. DIY -&gt; D-I-Y. (Default value = True)</p> </li> <li> <p>batch_size (int): Batch size of model to speed up inference. (Default value = 8)</p> </li> </ul>"},{"location":"phonemizer/#returns_1","title":"Returns","text":"<ul> <li>PhonemizerResult: Object containing original texts, phonemes, split texts, split phonemes, and predictions.</li> </ul>"},{"location":"phonemizer/#from_checkpoint","title":"from_checkpoint","text":"<pre><code>def from_checkpoint(cls, checkpoint_path, device, lang_phoneme_dict)\n</code></pre> <p>Initializes a Phonemizer object from a model checkpoint (.pt file).</p>"},{"location":"phonemizer/#args_3","title":"Args","text":"<ul> <li> <p>checkpoint_path (str): Path to the .pt checkpoint file.</p> </li> <li> <p>device (str): Device to send the model to ('cpu' or 'cuda'). (Default value = 'cpu')</p> </li> <li> <p>lang_phoneme_dict (Dict[str, Dict[str, str]], optional): Word-phoneme dictionary for each language.</p> </li> </ul>"},{"location":"phonemizer/#returns_2","title":"Returns","text":"<ul> <li>Phonemizer: Phonemizer object carrying the loaded model and, optionally, a phoneme dictionary.</li> </ul>"},{"location":"preprocess/","title":"preprocess","text":""},{"location":"preprocess/#preprocess","title":"preprocess","text":"<pre><code>def preprocess(config_file, train_data, val_data, deduplicate_train_data)\n</code></pre> <p>Preprocesses a given dataset to enable model training. The preprocessing result is stored in a folder provied by the config.</p>"},{"location":"preprocess/#args","title":"Args","text":"<ul> <li> <p>config_file (str): Path to the config.yaml that provides all necessary hyperparameters.</p> </li> <li> <p>train_data (List[Tuple[str, Iterable[str], Iterable[str]]]): Training data as a list of Tuples (language, grapheme sequence, phoneme sequence).</p> </li> <li> <p>val_data (List[Tuple[str, Iterable[str], Iterable[str]]], optional): Validation data as a list of Tuples (language, grapheme sequence, phoneme sequence).</p> </li> <li> <p>deduplicate_train_data (bool): Whether to deduplicate multiple occurences of the same word,                               the first is taken (Default value = True).</p> </li> </ul>"},{"location":"preprocess/#returns","title":"Returns","text":"<ul> <li>None: the preprocessing result is stored in a folder provided by the config.</li> </ul>"},{"location":"result/","title":"Result","text":""},{"location":"result/#class-prediction","title":"class Prediction","text":"<p>Container for single word prediction result.</p>"},{"location":"result/#__init__","title":"__init__","text":"<pre><code>def __init__(word, phonemes, phoneme_tokens, confidence, token_probs)\n</code></pre> <p>Initializes a Prediction object.</p>"},{"location":"result/#args","title":"Args","text":"<ul> <li> <p>word (str): Original word to predict.</p> </li> <li> <p>phonemes (str): Predicted phonemes (without special tokens).</p> </li> <li> <p>phoneme_tokens (List[str]): Predicted phoneme tokens (including special tokens).</p> </li> <li> <p>confidence (float): Total confidence of result.</p> </li> <li> <p>token_probs (List[float]): Probability of each phoneme token.</p> </li> </ul>"},{"location":"result/#class-phonemizerresult","title":"class PhonemizerResult","text":"<p>Container for phonemizer output.</p>"},{"location":"result/#__init___1","title":"__init__","text":"<pre><code>def __init__(text, phonemes, split_text, split_phonemes, predictions)\n</code></pre> <p>Initializes a PhonemizerResult object.</p>"},{"location":"result/#args_1","title":"Args","text":"<ul> <li> <p>text (List[str]): List of input texts.</p> </li> <li> <p>phonemes (List[str]): List of output phonemes.</p> </li> <li> <p>split_text (List[List[str]]): List of texts, where each text is split into words and special chars.</p> </li> <li> <p>split_phonemes (List[List[str]]): List of phonemes corresponding to split_text.</p> </li> <li> <p>predictions (Dict[str, Prediction]): Dictionary with entries word to Tuple (phoneme, probability).</p> </li> </ul>"},{"location":"train/","title":"train","text":""},{"location":"train/#train","title":"train","text":"<pre><code>def train(rank, num_gpus, config_file, checkpoint_file)\n</code></pre> <p>Runs training of a transformer model.</p>"},{"location":"train/#args","title":"Args","text":"<ul> <li> <p>rank (int): Device id</p> </li> <li> <p>num_gpus (int): Number of devices</p> </li> <li> <p>config_file (str): Path to the config.yaml that stores all necessary parameters.</p> </li> <li> <p>checkpoint_file (str, optional): Path to a model checkpoint to resume training for (e.g. latest_model.pt)</p> </li> </ul>"},{"location":"train/#returns","title":"Returns","text":"<ul> <li>None: The model checkpoints are stored in a folder provided by the config.</li> </ul>"},{"location":"model/model/","title":"Model","text":""},{"location":"model/model/#create_model","title":"create_model","text":"<pre><code>def create_model(model_type, config)\n</code></pre> <p>Initializes a model from a config for a given model type.</p>"},{"location":"model/model/#args","title":"Args","text":"<ul> <li> <p>model_type (ModelType): Type of model to be initialized.</p> </li> <li> <p>config (dict): Configuration containing hyperparams.</p> </li> </ul>"},{"location":"model/model/#load_checkpoint","title":"load_checkpoint","text":"<pre><code>def load_checkpoint(checkpoint_path, device)\n</code></pre> <p>Initializes a model from a checkpoint (.pt file).</p>"},{"location":"model/model/#args_1","title":"Args","text":"<ul> <li> <p>checkpoint_path (str): Path to checkpoint file (.pt).</p> </li> <li> <p>device (str): Device to put the model to ('cpu' or 'cuda').</p> </li> </ul>"},{"location":"model/model/#returns","title":"Returns","text":""},{"location":"model/model/#class-modeltype","title":"class ModelType","text":""},{"location":"model/model/#is_autoregressive","title":"is_autoregressive","text":"<pre><code>def is_autoregressive()\n</code></pre> <p>Returns: bool: Whether the model is autoregressive.</p>"},{"location":"model/model/#class-model","title":"class Model","text":""},{"location":"model/model/#__init__","title":"__init__","text":"<pre><code>def __init__()\n</code></pre>"},{"location":"model/model/#generate","title":"generate","text":"<pre><code>def generate(batch)\n</code></pre> <p>Generates phonemes for a text batch</p>"},{"location":"model/model/#args_2","title":"Args","text":"<ul> <li>batch (Dict[str, torch.Tensor]): Dictionary containing 'text' (tokenized text tensor),              'text_len' (text length tensor),              'start_index' (phoneme start indices for AutoregressiveTransformer)</li> </ul>"},{"location":"model/model/#returns_1","title":"Returns","text":"<ul> <li>Tuple[torch.Tensor, torch.Tensor]: The predictions. The first element is a tensor (phoneme tokens)</li> </ul>"},{"location":"model/model/#class-forwardtransformer","title":"class ForwardTransformer","text":""},{"location":"model/model/#__init___1","title":"__init__","text":"<pre><code>def __init__(encoder_vocab_size, decoder_vocab_size, d_model, d_fft, layers, dropout, heads)\n</code></pre>"},{"location":"model/model/#forward","title":"forward","text":"<pre><code>def forward(batch)\n</code></pre> <p>Forward pass of the model on a data batch.</p>"},{"location":"model/model/#args_3","title":"Args","text":"<ul> <li>batch (Dict[str, torch.Tensor]): Input batch entry 'text' (text tensor).</li> </ul>"},{"location":"model/model/#returns_2","title":"Returns","text":"<ul> <li>Tensor: Predictions.</li> </ul>"},{"location":"model/model/#generate_1","title":"generate","text":"<pre><code>def generate(batch)\n</code></pre> <p>Inference pass on a batch of tokenized texts.</p>"},{"location":"model/model/#args_4","title":"Args","text":"<ul> <li>batch (Dict[str, torch.Tensor]): Input batch with entry 'text' (text tensor).</li> </ul>"},{"location":"model/model/#returns_3","title":"Returns","text":"<ul> <li>Tuple: The first element is a Tensor (phoneme tokens) and the second element        is a tensor (phoneme token probabilities).</li> </ul>"},{"location":"model/model/#from_config","title":"from_config","text":"<pre><code>def from_config(cls, config)\n</code></pre>"},{"location":"model/model/#class-autoregressivetransformer","title":"class AutoregressiveTransformer","text":""},{"location":"model/model/#__init___2","title":"__init__","text":"<pre><code>def __init__(encoder_vocab_size, decoder_vocab_size, end_index, d_model, d_fft, encoder_layers, decoder_layers, dropout, heads)\n</code></pre>"},{"location":"model/model/#forward_1","title":"forward","text":"<pre><code>def forward(batch)\n</code></pre> <p>Foward pass of the model on a data batch.</p>"},{"location":"model/model/#args_5","title":"Args","text":"<ul> <li>batch (Dict[str, torch.Tensor]): Input batch with entries 'text' (text tensor) and 'phonemes'                                  (phoneme tensor for teacher forcing).</li> </ul>"},{"location":"model/model/#returns_4","title":"Returns","text":"<ul> <li>Tensor: Predictions.</li> </ul>"},{"location":"model/model/#generate_2","title":"generate","text":"<pre><code>def generate(batch, max_len)\n</code></pre> <p>Inference pass on a batch of tokenized texts.</p>"},{"location":"model/model/#args_6","title":"Args","text":"<ul> <li> <p>batch (Dict[str, torch.Tensor]): Dictionary containing the input to the model with entries 'text'                                  and 'start_index'</p> </li> <li> <p>max_len (int): Max steps of the autoregressive inference loop.</p> </li> </ul>"},{"location":"model/model/#returns_5","title":"Returns","text":"<ul> <li>Tuple: Predictions. The first element is a Tensor of phoneme tokens and the second element        is a Tensor of phoneme token probabilities.</li> </ul>"},{"location":"model/model/#from_config_1","title":"from_config","text":"<pre><code>def from_config(cls, config)\n</code></pre> <p>Initializes an autoregressive Transformer model from a config. Args: config (dict): Configuration containing the hyperparams.</p>"},{"location":"model/model/#returns_6","title":"Returns","text":"<ul> <li>AutoregressiveTransformer: Model object.</li> </ul>"},{"location":"model/predictor/","title":"Predictor","text":""},{"location":"model/predictor/#class-predictor","title":"class Predictor","text":"<p>Performs model predictions on a batch of inputs.</p>"},{"location":"model/predictor/#__init__","title":"__init__","text":"<pre><code>def __init__(model, preprocessor)\n</code></pre> <p>Initializes a Predictor object with a trained transformer model a preprocessor.</p>"},{"location":"model/predictor/#args","title":"Args","text":"<ul> <li> <p>model (Model): Trained transformer model.</p> </li> <li> <p>preprocessor (Preprocessor): Preprocessor corresponding to the model configuration.</p> </li> </ul>"},{"location":"model/predictor/#__call__","title":"__call__","text":"<pre><code>def __call__(words, lang, batch_size)\n</code></pre> <p>Predicts phonemes for a list of words.</p>"},{"location":"model/predictor/#args_1","title":"Args","text":"<ul> <li> <p>words (list): List of words to predict.</p> </li> <li> <p>lang (str): Language of texts.</p> </li> <li> <p>batch_size (int): Size of batch for model input to speed up inference.</p> </li> </ul>"},{"location":"model/predictor/#returns","title":"Returns","text":"<ul> <li>List[Prediction]: A list of result objects containing (word, phonemes, phoneme_tokens, token_probs, confidence)</li> </ul>"},{"location":"model/predictor/#from_checkpoint","title":"from_checkpoint","text":"<pre><code>def from_checkpoint(cls, checkpoint_path, device)\n</code></pre> <p>Initializes the predictor from a checkpoint (.pt file).</p>"},{"location":"model/predictor/#args_2","title":"Args","text":"<ul> <li> <p>checkpoint_path (str): Path to the checkpoint file (.pt).</p> </li> <li> <p>device (str): Device to load the model on ('cpu' or 'cuda'). (Default value = 'cpu').</p> </li> </ul>"},{"location":"model/predictor/#returns_1","title":"Returns","text":"<ul> <li>Predictor: Predictor object.</li> </ul>"},{"location":"model/utils/","title":"Utils","text":""},{"location":"model/utils/#get_dedup_tokens","title":"get_dedup_tokens","text":"<pre><code>def get_dedup_tokens(logits_batch)\n</code></pre> <p>Converts a batch of logits into the batch most probable tokens and their probabilities.</p>"},{"location":"model/utils/#args","title":"Args","text":"<ul> <li>logits_batch (Tensor): Batch of logits (N x T x V).</li> </ul>"},{"location":"model/utils/#returns","title":"Returns","text":"<ul> <li>Tuple: Deduplicated tokens. The first element is a tensor (token indices) and the second element</li> </ul>"},{"location":"model/utils/#_generate_square_subsequent_mask","title":"_generate_square_subsequent_mask","text":"<pre><code>def _generate_square_subsequent_mask(sz)\n</code></pre>"},{"location":"model/utils/#_make_len_mask","title":"_make_len_mask","text":"<pre><code>def _make_len_mask(inp)\n</code></pre>"},{"location":"model/utils/#_get_len_util_stop","title":"_get_len_util_stop","text":"<pre><code>def _get_len_util_stop(sequence, end_index)\n</code></pre>"},{"location":"model/utils/#_trim_util_stop","title":"_trim_util_stop","text":"<pre><code>def _trim_util_stop(sequence, end_index)\n</code></pre>"},{"location":"model/utils/#class-positionalencoding","title":"class PositionalEncoding","text":""},{"location":"model/utils/#__init__","title":"__init__","text":"<pre><code>def __init__(d_model, dropout, max_len)\n</code></pre> <p>Initializes positional encoding.</p>"},{"location":"model/utils/#args_1","title":"Args","text":"<ul> <li> <p>d_model (int): Dimension of model.</p> </li> <li> <p>dropout (float): Dropout after positional encoding.</p> </li> <li> <p>max_len: Max length of precalculated position sequence.</p> </li> </ul>"},{"location":"model/utils/#forward","title":"forward","text":"<pre><code>def forward(x)\n</code></pre>"},{"location":"preprocessing/text/","title":"Text","text":""},{"location":"preprocessing/text/#class-languagetokenizer","title":"class LanguageTokenizer","text":"<p>Simple tokenizer for language to index mapping.</p>"},{"location":"preprocessing/text/#__init__","title":"__init__","text":"<pre><code>def __init__(languages)\n</code></pre> <p>Initializes a language tokenizer for a list of languages.</p>"},{"location":"preprocessing/text/#args","title":"Args","text":"<ul> <li>languages (List[str]): List of languages, e.g. ['de', 'en'].</li> </ul>"},{"location":"preprocessing/text/#__call__","title":"__call__","text":"<pre><code>def __call__(lang)\n</code></pre> <p>Maps the language to an index.</p>"},{"location":"preprocessing/text/#args_1","title":"Args","text":"<ul> <li>lang (str): Language to be mapped, e.g. 'de'.</li> </ul>"},{"location":"preprocessing/text/#returns","title":"Returns","text":"<ul> <li>int: Index of language.</li> </ul>"},{"location":"preprocessing/text/#decode","title":"decode","text":"<pre><code>def decode(index)\n</code></pre> <p>Inverts the index mapping of a language.</p>"},{"location":"preprocessing/text/#args_2","title":"Args","text":"<ul> <li>index (int): Index of language.</li> </ul>"},{"location":"preprocessing/text/#returns_1","title":"Returns","text":"<ul> <li>str: Language for the given index.</li> </ul>"},{"location":"preprocessing/text/#class-sequencetokenizer","title":"class SequenceTokenizer","text":"<p>Tokenizes text and optionally attaches language-specific start index (and non-specific end index).</p>"},{"location":"preprocessing/text/#__init___1","title":"__init__","text":"<pre><code>def __init__(symbols, languages, char_repeats, lowercase, append_start_end, pad_token, end_token)\n</code></pre> <p>Initializes a SequenceTokenizer object.</p>"},{"location":"preprocessing/text/#args_3","title":"Args","text":"<ul> <li> <p>symbols (List[str]): Character (or phoneme) symbols.</p> </li> <li> <p>languages (List[str]): List of languages.</p> </li> <li> <p>char_repeats (int): Number of repeats for each character to allow the forward model to map to longer      phoneme sequences. Example</p> </li> <li> <p>lowercase (bool): Whether to lowercase the input word.</p> </li> <li> <p>append_start_end (bool): Whether to append special start and end tokens. Start and end tokens are      index mappings of the chosen language.</p> </li> <li> <p>pad_token (str): Special pad token for index 0.</p> </li> <li> <p>end_token (str): Special end of sequence token.</p> </li> </ul>"},{"location":"preprocessing/text/#__call___1","title":"__call__","text":"<pre><code>def __call__(sentence, language)\n</code></pre> <p>Maps a sequence of symbols for a language to a sequence of indices.</p>"},{"location":"preprocessing/text/#args_4","title":"Args","text":"<ul> <li> <p>sentence  (Iterable[str]): Sentence (or word) as a sequence of symbols.</p> </li> <li> <p>language (str): Language for the mapping that defines the start and end token indices.</p> </li> </ul>"},{"location":"preprocessing/text/#returns_2","title":"Returns","text":"<ul> <li>List[int]: Sequence of token indices.</li> </ul>"},{"location":"preprocessing/text/#decode_1","title":"decode","text":"<pre><code>def decode(sequence, remove_special_tokens)\n</code></pre> <p>Maps a sequence of indices to a sequence of symbols.</p>"},{"location":"preprocessing/text/#args_5","title":"Args","text":"<ul> <li> <p>sequence (Iterable[int]): Encoded sequence to be decoded.</p> </li> <li> <p>remove_special_tokens (bool): Whether to remove special tokens such as pad or start and end tokens. (Default value = False)</p> </li> <li> <p>sequence: Iterable[int]</p> </li> </ul>"},{"location":"preprocessing/text/#returns_3","title":"Returns","text":"<ul> <li>List[str]: Decoded sequence of symbols.</li> </ul>"},{"location":"preprocessing/text/#class-preprocessor","title":"class Preprocessor","text":"<p>Preprocesses data for a phonemizer training session.</p>"},{"location":"preprocessing/text/#__init___2","title":"__init__","text":"<pre><code>def __init__(lang_tokenizer, text_tokenizer, phoneme_tokenizer)\n</code></pre> <p>Initializes a preprocessor object.</p>"},{"location":"preprocessing/text/#args_6","title":"Args","text":"<ul> <li> <p>lang_tokenizer (LanguageTokenizer): Tokenizer for input language.</p> </li> <li> <p>text_tokenizer (SequenceTokenizer): Tokenizer for input text.</p> </li> <li> <p>phoneme_tokenizer (SequenceTokenizer): Tokenizer for output phonemes.</p> </li> </ul>"},{"location":"preprocessing/text/#__call___2","title":"__call__","text":"<pre><code>def __call__(item)\n</code></pre> <p>Preprocesses a data point.</p>"},{"location":"preprocessing/text/#args_7","title":"Args","text":"<ul> <li>item (Tuple): Data point comprised of (language, input text, output phonemes).</li> </ul>"},{"location":"preprocessing/text/#from_config","title":"from_config","text":"<pre><code>def from_config(cls, config)\n</code></pre> <p>Initializes a preprocessor from a config.</p>"},{"location":"preprocessing/text/#args_8","title":"Args","text":"<ul> <li>config (Dict[str, Any]): Dictionary containing preprocessing hyperparams.</li> </ul>"},{"location":"preprocessing/text/#returns_4","title":"Returns","text":"<ul> <li>Preprocessor: Preprocessor object.</li> </ul>"},{"location":"preprocessing/utils/","title":"Utils","text":""},{"location":"preprocessing/utils/#_product","title":"_product","text":"<pre><code>def _product(probs)\n</code></pre>"},{"location":"preprocessing/utils/#_batchify","title":"_batchify","text":"<pre><code>def _batchify(input, batch_size)\n</code></pre>"},{"location":"training/dataset/","title":"Dataset","text":""},{"location":"training/dataset/#collate_dataset","title":"collate_dataset","text":"<pre><code>def collate_dataset(batch)\n</code></pre>"},{"location":"training/dataset/#new_dataloader","title":"new_dataloader","text":"<pre><code>def new_dataloader(dataset_file, batch_size, drop_last, use_binning, use_ddp)\n</code></pre>"},{"location":"training/dataset/#class-phonemizerdataset","title":"class PhonemizerDataset","text":""},{"location":"training/dataset/#__init__","title":"__init__","text":"<pre><code>def __init__(items)\n</code></pre>"},{"location":"training/dataset/#__getitem__","title":"__getitem__","text":"<pre><code>def __getitem__(index)\n</code></pre>"},{"location":"training/dataset/#__len__","title":"__len__","text":"<pre><code>def __len__()\n</code></pre>"},{"location":"training/dataset/#class-binnedlengthsampler","title":"class BinnedLengthSampler","text":""},{"location":"training/dataset/#__init___1","title":"__init__","text":"<pre><code>def __init__(phoneme_lens, batch_size, bin_size, seed)\n</code></pre>"},{"location":"training/dataset/#__iter__","title":"__iter__","text":"<pre><code>def __iter__()\n</code></pre>"},{"location":"training/dataset/#__len___1","title":"__len__","text":"<pre><code>def __len__()\n</code></pre>"},{"location":"training/decorators/","title":"Decorators","text":""},{"location":"training/decorators/#ignore_exception","title":"ignore_exception","text":"<pre><code>def ignore_exception(f)\n</code></pre>"},{"location":"training/evaluation/","title":"Evaluation","text":""},{"location":"training/evaluation/#evaluate_samples","title":"evaluate_samples","text":"<pre><code>def evaluate_samples(lang_samples)\n</code></pre> <p>Calculates word and phoneme error rates per language and their mean across languages</p>"},{"location":"training/evaluation/#args","title":"Args","text":"<ul> <li>lang_samples (Dict): Data to evaluate. Contains languages as keys and list of result samples as values.                      Prediction samples is given as a List of Tuples, where each Tuple is a tokenized representation of                      (text, result, target).</li> </ul>"},{"location":"training/evaluation/#returns","title":"Returns","text":"<ul> <li>Dict: Evaluation result carrying word and phoneme error rates per language.</li> </ul>"},{"location":"training/losses/","title":"Losses","text":""},{"location":"training/losses/#class-crossentropyloss","title":"class CrossEntropyLoss","text":""},{"location":"training/losses/#__init__","title":"__init__","text":"<pre><code>def __init__()\n</code></pre>"},{"location":"training/losses/#forward","title":"forward","text":"<pre><code>def forward(pred, batch)\n</code></pre> <p>Forward pass of the CrossEntropyLoss module on a batch.</p>"},{"location":"training/losses/#args","title":"Args","text":"<ul> <li> <p>pred: torch.Tensor</p> </li> <li> <p>batch: Dict[str</p> </li> <li> <p>torch.Tensor]: </p> </li> </ul>"},{"location":"training/losses/#returns","title":"Returns","text":""},{"location":"training/losses/#class-ctcloss","title":"class CTCLoss","text":""},{"location":"training/losses/#__init___1","title":"__init__","text":"<pre><code>def __init__()\n</code></pre>"},{"location":"training/losses/#forward_1","title":"forward","text":"<pre><code>def forward(pred, batch)\n</code></pre> <p>Forward pass of the CTCLoss module on a batch.</p>"},{"location":"training/losses/#args_1","title":"Args","text":"<ul> <li> <p>pred: torch.Tensor</p> </li> <li> <p>batch: Dict[str</p> </li> <li> <p>ext_len': input text lengths, 'phonemes_len'</p> </li> <li> <p>torch.Tensor]: </p> </li> </ul>"},{"location":"training/losses/#returns_1","title":"Returns","text":""},{"location":"training/metrics/","title":"Metrics","text":""},{"location":"training/metrics/#word_error","title":"word_error","text":"<pre><code>def word_error(predicted, target)\n</code></pre> <p>Calculates the word error rate of a single word result.</p>"},{"location":"training/metrics/#args","title":"Args","text":"<ul> <li> <p>predicted: List[Union[str</p> </li> <li> <p>target: List[Union[str</p> </li> <li> <p>int]]: </p> </li> </ul>"},{"location":"training/metrics/#returns","title":"Returns","text":""},{"location":"training/metrics/#phoneme_error","title":"phoneme_error","text":"<pre><code>def phoneme_error(predicted, target)\n</code></pre> <p>Calculates the phoneme error rate of a single result based on the Levenshtein distance.</p>"},{"location":"training/metrics/#args_1","title":"Args","text":"<ul> <li> <p>predicted: List[Union[str</p> </li> <li> <p>target: List[Union[str</p> </li> <li> <p>int]]: </p> </li> </ul>"},{"location":"training/metrics/#returns_1","title":"Returns","text":""},{"location":"training/trainer/","title":"Trainer","text":""},{"location":"training/trainer/#class-trainer","title":"class Trainer","text":"<p>Performs model training.</p>"},{"location":"training/trainer/#__init__","title":"__init__","text":"<pre><code>def __init__(checkpoint_dir, device, rank, use_ddp, loss_type)\n</code></pre> <p>Initializes a Trainer object.</p>"},{"location":"training/trainer/#args","title":"Args","text":"<ul> <li> <p>checkpoint_dir (Path): Directory to store the model checkpoints.</p> </li> <li> <p>device (torch.device): Device used for training</p> </li> <li> <p>rank (int): Rank of the current device</p> </li> <li> <p>use_ddp (bool): Flag whether DDP is used for training</p> </li> <li> <p>loss_type (str): Type of loss</p> </li> </ul>"},{"location":"training/trainer/#train","title":"train","text":"<pre><code>def train(model, checkpoint, store_phoneme_dict_in_model)\n</code></pre> <p>Performs training of a transformer model.</p>"},{"location":"training/trainer/#args_1","title":"Args","text":"<ul> <li> <p>model (Model): Model to be trained (can be a fresh model or restored from a checkpoint).</p> </li> <li> <p>checkpoint (Dict[str, Any]): Dictionary with entries 'optimizer'</p> </li> <li> <p>store_phoneme_dict_in_model (bool): Whether to store a dictionary of word-phoneme mappings                                     in the model checkpoint so that it can be automatically                                     loaded by a Phonemizer object.</p> </li> </ul>"},{"location":"training/trainer/#returns","title":"Returns","text":"<ul> <li>None: the checkpoints will be stored in a folder provided when instantiating a Trainer.</li> </ul>"},{"location":"utils/io/","title":"Io","text":""},{"location":"utils/io/#read_config","title":"read_config","text":"<pre><code>def read_config(path)\n</code></pre> <p>Reads the config dictionary from the yaml file.</p>"},{"location":"utils/io/#args","title":"Args","text":"<ul> <li>path (str): Path to the .yaml file.</li> </ul>"},{"location":"utils/io/#returns","title":"Returns","text":"<ul> <li>Dict[str, Any]: Configuration.</li> </ul>"},{"location":"utils/io/#save_config","title":"save_config","text":"<pre><code>def save_config(config, path)\n</code></pre> <p>Saves the config as a yaml file.</p>"},{"location":"utils/io/#args_1","title":"Args","text":"<ul> <li> <p>config (Dict[str, Any]): Configuration.</p> </li> <li> <p>path (str): Path to save the dictionary to (.yaml).</p> </li> </ul>"},{"location":"utils/io/#get_files","title":"get_files","text":"<pre><code>def get_files(path, extension)\n</code></pre> <p>Recursively retrieves all files with a given extension from a folder.</p>"},{"location":"utils/io/#args_2","title":"Args","text":"<ul> <li> <p>path (str): Path to the folder to retrieve files from.</p> </li> <li> <p>extension (str): Extension of files to be retrieved (Default value = '.wav').</p> </li> </ul>"},{"location":"utils/io/#returns_1","title":"Returns","text":"<ul> <li>List[Path]: List of paths to the found files.</li> </ul>"},{"location":"utils/io/#pickle_binary","title":"pickle_binary","text":"<pre><code>def pickle_binary(data, file)\n</code></pre> <p>Pickles a given object to a binary file.</p>"},{"location":"utils/io/#args_3","title":"Args","text":"<ul> <li> <p>data (object): Object to be pickled.</p> </li> <li> <p>file (Union[str, Path]): Path to destination file (use the .pkl extension).</p> </li> </ul>"},{"location":"utils/io/#unpickle_binary","title":"unpickle_binary","text":"<pre><code>def unpickle_binary(file)\n</code></pre> <p>Unpickles a given binary file to an object</p>"},{"location":"utils/io/#args_4","title":"Args","text":"<ul> <li>file (nion[str, Path]): Path to the file.</li> </ul>"},{"location":"utils/io/#returns_2","title":"Returns","text":"<ul> <li>object: Unpickled object.</li> </ul>"},{"location":"utils/io/#to_device","title":"to_device","text":"<pre><code>def to_device(batch, device)\n</code></pre> <p>Sends a batch of data to the given torch devicee (cpu or cuda).</p>"},{"location":"utils/io/#args_5","title":"Args","text":"<ul> <li> <p>batch (Dict[str, torch.Tensor]): Batch to be send to the device.</p> </li> <li> <p>device (torch.device): Device (either torch.device('cpu') or torch.device('cuda').</p> </li> </ul>"},{"location":"utils/io/#returns_3","title":"Returns","text":"<ul> <li>Dict[str, torch.Tensor]: The batch at the given device.</li> </ul>"},{"location":"utils/logging/","title":"Logging","text":""},{"location":"utils/logging/#get_logger","title":"get_logger","text":"<pre><code>def get_logger(name)\n</code></pre> <p>Creates a logger object for a given name.</p>"},{"location":"utils/logging/#args","title":"Args","text":"<ul> <li>name (str): Name of the logger.</li> </ul>"},{"location":"utils/logging/#returns","title":"Returns","text":"<ul> <li>Logger: Logger object with given name.</li> </ul>"}]}